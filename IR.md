# 1. 倒排索引布尔检索
词项-文档矩阵  
采用定长数组存储文档ID是不可行的  
通常采用变长表的方式（vector、list）
每个词项中按照docID排序  
布尔查询的处理：  
- AND查询，倒排记录表求交集，复杂度O(len1+len2)；  
- OR查询，倒排记录表求并集，复杂度O(1)；
- NOT查询，倒排记录表的减，复杂度O(len1+len2)；

布尔表达式的查询优化：
- AND查询，从长度最小的表开始合并；  
- 布尔表达式转化为合取范式，结合AND查询优化策略；

优缺点  
# 2. 词汇表与倒排记录表  
中文分词方法：  
- 词典：正向最大匹配和逆向最大匹配；新词问题二义问题；解决：规则+统计；  
- 规则+统计，条件随机场；
- 搜索引擎中的中文分词法：大词典+统计+启发式规则；  

去除停用词：词典  
现代搜索引擎倾向于不去除停用词：良好的索引压缩之后停用词占据资源很小，良好的查询优化策略之后不会增加查询开销，停用词有时候还是有大用处的。  
例子：to be or not to be.  
词条归一化成词项：同义词归一化，拼写错误处理，词形合并，词干还原
归一化工具：stemmer  
快速倒排记录表合并：skiplist  
短语查询：中国科学院：中国 AND 科学院 是不准确的  
解决方法：  
1.双词索引，两个词项合并成一个词项  
更长的短语查询：拆分成基于双词索引的布尔表达式  
扩展双词索引：对索引文档进行词性标注，满足词性规则的也划分为双词。例如catcher in the rye  
讲query也切分为扩展双词  
2.带位置信息的索引  
合并的时候考虑位置匹配，例子 to be or not to be.  
带位置信息的索引可处理临近查询，而双词索引则不能  
索引压缩可处理位置信息和双词索引带来的空间开销，一般是非位置索引的2-4倍。  
还可采用混合索引  
# 3. 词典与容错式检索
词项定位 两种数据结构：哈希表、树  
有些IR系统采用哈希表，有些IR系统采用树  
取决于词项数目，访问频次，更新频次  
哈希表的查询时间是常数，缺点：无法处理词项的变形和纠错、不支持前缀搜索、重新哈希。  
树：主要是B树，B+树。  
通配符查询的处理：  
1.mon\*采用B树查询非常容易，只需要返回mon子树的词项即可。    
\*mon可以将所有词项倒过来，构建一棵B树。  
通配符在中间的时候使用B树搜索的开销很大：mon\*st  
分别求满足mon\*和\*st的匹配词项，然后求交集，开销很大。  
2.轮排索引（轮排树）：  
将每个通配查询旋转，使得\*出现在末尾，将每个旋转之后的结果放在词典中。即在索引前面再加一层索引，索引用B树来组织。  
轮排索引的空间要大四倍以上。  
3.k-gram索引  
构建一个倒排索引，此时词典部分是所有的k-gram，倒排记录表部分是包含某个k-gram的所有词项  
相当于对词项再构建一个倒排索引(二级索引)  
2-gram拆分的例子：mon\*拆分成 $m AND mo AND on  
需要后续过滤：例如moon  
k-gram的空间消耗较小，轮排索引不需要后续过滤。  
拼写错误处理：  
两种拼写纠正的方法：词袋法，上下文敏感法。  
词袋法：单词间距离的计算：编辑距离(DP)、带权重的编辑距离(基于电脑键盘，手机键盘)、k-gram重叠率。  
k-gram拼写纠正：使用k-gram索引，根据jaccard相似度设定阈值减少匹配数目。  
上下文敏感的拼写纠正：统计结果、从历史检索库中检索  
基于发音的拼写错误：略  
拼写错误的处理：一般只给出一个结果，拼写错误检查的开销很大，但是拼写错误的检查，主流搜索引擎做的很好。  
# 4. 索引构建  
两种索引构建算法：BSBI(简单):基于块的排序索引构建算法  
SPIMI(更符合实际情况):内存式单遍扫描索引构建算法    
语料库：路透社1995-1996年所有新闻报道  
BSBI：构建倒排索引：词典与词项对应的倒排记录表。  
BSBI的主要思想是基于排序，遍历不到最后一篇文档的时候，倒排索引都是不完整的。  
基本思路：对每个块: (i) 倒排记录累积到10,000,000条, (ii) 在内存中排序, (iii) 写回磁盘，（iv）最后将所有的块合并成一个大的有序的倒排索引  
SPIMI：  
关键思想1: 对每个块都产生一个独立的词典–——不需要在块之间进行term-termID的映射  
关键思想2: 对倒排记录表不排序，按照他们出现的先后顺序排列  
基础上述思想可以对每个块生成一个完整的倒排索引  
这些独立的索引最后合并一个大索引  
对SPIMI进行索引压缩之后会更加高效  
分布式索引构建：MapReduce任务  
parser：1.主节点将一个数据片分配给一台空闲的分析器；2.分析器一次度一篇文档，输出词项文档对；3.按照词项首字母对词项文档对进行分区。  
inverter：倒排器收集对应某一词项分区的词项文档对，排序并写进倒排记录表。  
动态索引构建：新增的文档加入辅助索引中，空闲时间与主索引合并。  
对数合并算法  
# 5. 索引压缩 
无损压缩  
词项数目：heaps拟合，M=kT^b T是文档集大小（词条个数）  
词项分布：Zipf定律：第i常见的词项的频率cf(i)和1/i成正比，幂律分布  
词典压缩：将整部词典看成单一字符串，每个词项有一个指针指向特定位置。改进：将词典分块，每一块的块头有一个词项指针，字符串中的每个词项前面加上词项的长度。  
  






















